{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e66284fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sbn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82d56f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['PG-13', 'Unrated', 'PG', 'R', 'G', 'TV-14', 'TV-MA', 'TV-PG',\n",
       "       'NC-17', 'TV-Y7', 'TV-G', 'C13', 'Approved', 'C18', 'C16', 'C12',\n",
       "       'MA-17', 'TV-Y7-FV', 'AO', 'TV-Y', 'M', '(Banned)', 'C6', 'PG-12',\n",
       "       'GP', 'U', 'C7', 'C15', 'AL', 'C9'], dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Cleaned_Data.csv')\n",
    "df = df.dropna(subset=['Writer'])\n",
    "df['Certificate'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49a2fcf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kingk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['PG-13', 'Unrated', 'PG', 'R', 'G', 'TV-14', 'TV-MA', 'TV-PG',\n",
       "       'NC-17', 'TV-Y7', 'TV-G', 'C13', 'Approved', 'C18', 'C16', 'C12',\n",
       "       'MA-17', 'TV-Y7-FV', 'AO', 'TV-Y', 'M', '(Banned)', 'C6', 'PG-12',\n",
       "       'GP', 'U', 'C7', 'C15', 'AL', 'C9'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stopwords_list = stopwords.words('english')\n",
    "\n",
    "stopwords_list\n",
    "stopwords_list.append(\" \")\n",
    "stopwords_list.append(\"\")\n",
    "stopwords_list.extend([chr(i) for i in range(ord('a'), ord('z') + 1)])\n",
    "\n",
    "# Define a function to split text into words and remove specified words\n",
    "def split_into_words_and_remove_stopwords(text, stopwords):\n",
    "    # Split text using various separators (space, period, comma)\n",
    "    words = re.split(r'\\s+|[,\\.:!?\"&]', text)\n",
    "    # Remove specified stopwords from the list\n",
    "    words = [word.lower() for word in words if word.lower() not in stopwords]\n",
    "    return words\n",
    "\n",
    "\n",
    "# Apply the function to the \"storyline\" column\n",
    "df['Storyline'] = df['Storyline'].apply(lambda x: split_into_words_and_remove_stopwords(x, stopwords_list))\n",
    "df['Genre'] = df['Genre'].apply(lambda x: split_into_words_and_remove_stopwords(x, stopwords_list))\n",
    "df['Stars'] = df['Stars'].apply(lambda x: x.split(','))\n",
    "df['Writer'] = df['Writer'].apply(lambda x: x.split(','))\n",
    "\n",
    "# Display the DataFrame\n",
    "df['Certificate'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a80f291a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Certificate</th>\n",
       "      <th>Poster</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Director</th>\n",
       "      <th>Writer</th>\n",
       "      <th>Stars</th>\n",
       "      <th>Storyline</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Rating Count</th>\n",
       "      <th>Director_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>https://m.media-amazon.com/images/M/MV5BMTMxNT...</td>\n",
       "      <td>[action, crime, drama]</td>\n",
       "      <td>Christopher Nolan</td>\n",
       "      <td>[Jonathan Nolan,  Christopher Nolan,  David S....</td>\n",
       "      <td>[Christian Bale,  Heath Ledger,  Aaron Eckhart...</td>\n",
       "      <td>[menace, known, joker, wreaks, havoc, chaos, p...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2800000.0</td>\n",
       "      <td>0.179725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Lord of the Rings: The Return of the King</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>https://m.media-amazon.com/images/M/MV5BNzA5ZD...</td>\n",
       "      <td>[action, adventure, drama]</td>\n",
       "      <td>Peter Jackson</td>\n",
       "      <td>[J.R.R. Tolkien,  Fran Walsh,  Philippa Boyens]</td>\n",
       "      <td>[Elijah Wood,  Viggo Mortensen,  Ian McKellen,...</td>\n",
       "      <td>[gandalf, aragorn, lead, world, men, sauron's,...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1900000.0</td>\n",
       "      <td>0.726021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dr. Babasaheb Ambedkar</td>\n",
       "      <td>Unrated</td>\n",
       "      <td>https://m.media-amazon.com/images/M/MV5BNGNjZD...</td>\n",
       "      <td>[biography, history]</td>\n",
       "      <td>Jabbar Patel</td>\n",
       "      <td>[Daya Pawar,  Arun Sadhu,  Sooni Taraporevala]</td>\n",
       "      <td>[Mammootty,  Sonali Kulkarni,  Mohan Gokhale, ...</td>\n",
       "      <td>[biopic, ambedkar, known, mainly, contribution...</td>\n",
       "      <td>8.9</td>\n",
       "      <td>2700.0</td>\n",
       "      <td>0.383982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Lord of the Rings: The Fellowship of the Ring</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>https://m.media-amazon.com/images/M/MV5BN2EyZj...</td>\n",
       "      <td>[action, adventure, drama]</td>\n",
       "      <td>Peter Jackson</td>\n",
       "      <td>[J.R.R. Tolkien,  Fran Walsh,  Philippa Boyens]</td>\n",
       "      <td>[Elijah Wood,  Ian McKellen,  Orlando Bloom,  ...</td>\n",
       "      <td>[meek, hobbit, shire, eight, companions, set, ...</td>\n",
       "      <td>8.8</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>0.726021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Lord of the Rings: The Two Towers</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>https://m.media-amazon.com/images/M/MV5BZGMxZT...</td>\n",
       "      <td>[action, adventure, drama]</td>\n",
       "      <td>Peter Jackson</td>\n",
       "      <td>[J.R.R. Tolkien,  Fran Walsh,  Philippa Boyens]</td>\n",
       "      <td>[Elijah Wood,  Ian McKellen,  Viggo Mortensen,...</td>\n",
       "      <td>[frodo, sam, edge, closer, mordor, help, shift...</td>\n",
       "      <td>8.8</td>\n",
       "      <td>1700000.0</td>\n",
       "      <td>0.726021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23772</th>\n",
       "      <td>Erkek Tarafi Testosteron</td>\n",
       "      <td>Unrated</td>\n",
       "      <td>https://m.media-amazon.com/images/M/MV5BZjUwNW...</td>\n",
       "      <td>[comedy]</td>\n",
       "      <td>Ilksen Basarir</td>\n",
       "      <td>[Kemal Aydogan,  Ilksen Basarir,  Mert Firat]</td>\n",
       "      <td>[Onur Ünsal,  Mert Firat,  Emre Karayel]</td>\n",
       "      <td>[starts, bride, kissing, one, guests]</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1284.0</td>\n",
       "      <td>0.373536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23774</th>\n",
       "      <td>Hich</td>\n",
       "      <td>Unrated</td>\n",
       "      <td>https://m.media-amazon.com/images/M/MV5BYTY0Y2...</td>\n",
       "      <td>[comedy, drama]</td>\n",
       "      <td>Abdolreza Kahani</td>\n",
       "      <td>[Abdolreza Kahani,  Hossein Mahkam]</td>\n",
       "      <td>[Ahmad Mehranfar,  Mehran Ahmadi,  Nayereh Far...</td>\n",
       "      <td>[man, kind, disease, eats, lot, enters, poor, ...</td>\n",
       "      <td>6.8</td>\n",
       "      <td>1128.0</td>\n",
       "      <td>0.005065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23775</th>\n",
       "      <td>Kummeli Alivuokralainen</td>\n",
       "      <td>Unrated</td>\n",
       "      <td>https://m.media-amazon.com/images/M/MV5BODI2MD...</td>\n",
       "      <td>[comedy]</td>\n",
       "      <td>Matti Grönberg</td>\n",
       "      <td>[Timo Kahilainen,  Heikki Vihinen,  Anttu Harlin]</td>\n",
       "      <td>[Mikko Kivinen,  Heikki Silvennoinen,  Timo Ka...</td>\n",
       "      <td>[farce, blackmailing, kidney, transplant, oper...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1398.0</td>\n",
       "      <td>0.619421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23776</th>\n",
       "      <td>Någon Annanstans</td>\n",
       "      <td>Unrated</td>\n",
       "      <td>https://m.media-amazon.com/images/M/MV5BMjA0Nz...</td>\n",
       "      <td>[drama, romance]</td>\n",
       "      <td>Hiwa Abbasi</td>\n",
       "      <td>[Hiwa Abbasi]</td>\n",
       "      <td>[Ruth Anianson,  Arefeh Behbakht,  Lina Burström]</td>\n",
       "      <td>[said, main, character, film, another, place, ...</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3333.0</td>\n",
       "      <td>0.363406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23777</th>\n",
       "      <td>Chambaili</td>\n",
       "      <td>Unrated</td>\n",
       "      <td>https://m.media-amazon.com/images/M/MV5BMTYxND...</td>\n",
       "      <td>[crime, drama, thriller]</td>\n",
       "      <td>Ismail Jillani</td>\n",
       "      <td>[Shahzad Nawaz]</td>\n",
       "      <td>[Khalid Ahmed,  Shafqat Cheema,  Ehteshamuddin]</td>\n",
       "      <td>[group, friends, led, circumstances, find, cro...</td>\n",
       "      <td>7.7</td>\n",
       "      <td>1115.0</td>\n",
       "      <td>0.378363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23436 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Name Certificate   \n",
       "0                                        The Dark Knight       PG-13  \\\n",
       "1          The Lord of the Rings: The Return of the King       PG-13   \n",
       "2                                 Dr. Babasaheb Ambedkar     Unrated   \n",
       "3      The Lord of the Rings: The Fellowship of the Ring       PG-13   \n",
       "4                  The Lord of the Rings: The Two Towers       PG-13   \n",
       "...                                                  ...         ...   \n",
       "23772                           Erkek Tarafi Testosteron     Unrated   \n",
       "23774                                               Hich     Unrated   \n",
       "23775                            Kummeli Alivuokralainen     Unrated   \n",
       "23776                                   Någon Annanstans     Unrated   \n",
       "23777                                          Chambaili     Unrated   \n",
       "\n",
       "                                                  Poster   \n",
       "0      https://m.media-amazon.com/images/M/MV5BMTMxNT...  \\\n",
       "1      https://m.media-amazon.com/images/M/MV5BNzA5ZD...   \n",
       "2      https://m.media-amazon.com/images/M/MV5BNGNjZD...   \n",
       "3      https://m.media-amazon.com/images/M/MV5BN2EyZj...   \n",
       "4      https://m.media-amazon.com/images/M/MV5BZGMxZT...   \n",
       "...                                                  ...   \n",
       "23772  https://m.media-amazon.com/images/M/MV5BZjUwNW...   \n",
       "23774  https://m.media-amazon.com/images/M/MV5BYTY0Y2...   \n",
       "23775  https://m.media-amazon.com/images/M/MV5BODI2MD...   \n",
       "23776  https://m.media-amazon.com/images/M/MV5BMjA0Nz...   \n",
       "23777  https://m.media-amazon.com/images/M/MV5BMTYxND...   \n",
       "\n",
       "                            Genre           Director   \n",
       "0          [action, crime, drama]  Christopher Nolan  \\\n",
       "1      [action, adventure, drama]      Peter Jackson   \n",
       "2            [biography, history]       Jabbar Patel   \n",
       "3      [action, adventure, drama]      Peter Jackson   \n",
       "4      [action, adventure, drama]      Peter Jackson   \n",
       "...                           ...                ...   \n",
       "23772                    [comedy]     Ilksen Basarir   \n",
       "23774             [comedy, drama]   Abdolreza Kahani   \n",
       "23775                    [comedy]     Matti Grönberg   \n",
       "23776            [drama, romance]        Hiwa Abbasi   \n",
       "23777    [crime, drama, thriller]     Ismail Jillani   \n",
       "\n",
       "                                                  Writer   \n",
       "0      [Jonathan Nolan,  Christopher Nolan,  David S....  \\\n",
       "1        [J.R.R. Tolkien,  Fran Walsh,  Philippa Boyens]   \n",
       "2         [Daya Pawar,  Arun Sadhu,  Sooni Taraporevala]   \n",
       "3        [J.R.R. Tolkien,  Fran Walsh,  Philippa Boyens]   \n",
       "4        [J.R.R. Tolkien,  Fran Walsh,  Philippa Boyens]   \n",
       "...                                                  ...   \n",
       "23772      [Kemal Aydogan,  Ilksen Basarir,  Mert Firat]   \n",
       "23774                [Abdolreza Kahani,  Hossein Mahkam]   \n",
       "23775  [Timo Kahilainen,  Heikki Vihinen,  Anttu Harlin]   \n",
       "23776                                      [Hiwa Abbasi]   \n",
       "23777                                    [Shahzad Nawaz]   \n",
       "\n",
       "                                                   Stars   \n",
       "0      [Christian Bale,  Heath Ledger,  Aaron Eckhart...  \\\n",
       "1      [Elijah Wood,  Viggo Mortensen,  Ian McKellen,...   \n",
       "2      [Mammootty,  Sonali Kulkarni,  Mohan Gokhale, ...   \n",
       "3      [Elijah Wood,  Ian McKellen,  Orlando Bloom,  ...   \n",
       "4      [Elijah Wood,  Ian McKellen,  Viggo Mortensen,...   \n",
       "...                                                  ...   \n",
       "23772           [Onur Ünsal,  Mert Firat,  Emre Karayel]   \n",
       "23774  [Ahmad Mehranfar,  Mehran Ahmadi,  Nayereh Far...   \n",
       "23775  [Mikko Kivinen,  Heikki Silvennoinen,  Timo Ka...   \n",
       "23776  [Ruth Anianson,  Arefeh Behbakht,  Lina Burström]   \n",
       "23777    [Khalid Ahmed,  Shafqat Cheema,  Ehteshamuddin]   \n",
       "\n",
       "                                               Storyline  Rating   \n",
       "0      [menace, known, joker, wreaks, havoc, chaos, p...     9.0  \\\n",
       "1      [gandalf, aragorn, lead, world, men, sauron's,...     9.0   \n",
       "2      [biopic, ambedkar, known, mainly, contribution...     8.9   \n",
       "3      [meek, hobbit, shire, eight, companions, set, ...     8.8   \n",
       "4      [frodo, sam, edge, closer, mordor, help, shift...     8.8   \n",
       "...                                                  ...     ...   \n",
       "23772              [starts, bride, kissing, one, guests]     4.1   \n",
       "23774  [man, kind, disease, eats, lot, enters, poor, ...     6.8   \n",
       "23775  [farce, blackmailing, kidney, transplant, oper...     4.3   \n",
       "23776  [said, main, character, film, another, place, ...     4.4   \n",
       "23777  [group, friends, led, circumstances, find, cro...     7.7   \n",
       "\n",
       "       Rating Count  Director_encoded  \n",
       "0         2800000.0          0.179725  \n",
       "1         1900000.0          0.726021  \n",
       "2            2700.0          0.383982  \n",
       "3         2000000.0          0.726021  \n",
       "4         1700000.0          0.726021  \n",
       "...             ...               ...  \n",
       "23772        1284.0          0.373536  \n",
       "23774        1128.0          0.005065  \n",
       "23775        1398.0          0.619421  \n",
       "23776        3333.0          0.363406  \n",
       "23777        1115.0          0.378363  \n",
       "\n",
       "[23436 rows x 11 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be40cdc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['PG-13', 'Unrated', 'PG', 'R', 'G', 'TV-14', 'TV-MA', 'TV-PG',\n",
       "       'NC-17', 'TV-Y7', 'TV-G', 'C13', 'Approved', 'C18', 'C16', 'C12',\n",
       "       'MA-17', 'TV-Y7-FV', 'AO', 'TV-Y', 'M', '(Banned)', 'C6', 'PG-12',\n",
       "       'GP', 'U', 'C7', 'C15', 'AL', 'C9'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Certificate\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cc223029",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Storyline'] = [' '.join(row) for row in df['Storyline'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f108b2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df[df['Genre'].apply(lambda x: 'drama' in x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f48d6d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8536689419795221\n",
      "Recall: 0.4541622760800843\n",
      "F1-score: 0.5568475452196382\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Stratified Sampling: chia 70-30 ở True_df và False_df rồi kết hợp\n",
    "df_0 = df[df['Genre'].apply(lambda x: 'action' in x)]\n",
    "df_1 = df[df['Genre'].apply(lambda x: 'action' not in x)]\n",
    "\n",
    "# Chia thành tập huấn luyện và tập kiểm thử với tỉ lệ 70-30\n",
    "train_df_0, test_df_0 = train_test_split(df_0, test_size=0.2, random_state=42)\n",
    "train_df_1, test_df_1 = train_test_split(df_1, test_size=0.2, random_state=42)\n",
    "\n",
    "# Kết hợp lại để tạo tập huấn luyện và tập kiểm thử cuối cùng\n",
    "train_df = pd.concat([train_df_0, train_df_1], axis=0)\n",
    "test_df = pd.concat([test_df_0, test_df_1], axis=0)\n",
    "\n",
    "X_train = [' '.join(row) for row in train_df['Storyline'].values]\n",
    "X_test = [' '.join(row) for row in test_df['Storyline'].values]\n",
    "y_train = ['action' in value for value in train_df['Genre'].values]\n",
    "y_test = ['action' in value for value in test_df['Genre'].values]\n",
    "\n",
    "# Sử dụng TF-IDF để biểu diễn văn bản\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Huấn luyện mô hình SVM\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Dự đoán trên tập kiểm tra\n",
    "y_pred = svm_model.predict(X_test_tfidf)\n",
    "\n",
    "# Đánh giá mô hình\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# In kq ra màn hình\n",
    "print(\"Accuracy: \" + str(accuracy))\n",
    "print(\"Recall: \" + str(recall))\n",
    "print(\"F1-score: \" + str(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5eea4b26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4742"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_0.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6566ee08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Director_encoded\n",
       "0.885882    27\n",
       "0.902422    25\n",
       "0.977999    24\n",
       "0.944444    22\n",
       "0.304843    22\n",
       "            ..\n",
       "0.591010     1\n",
       "0.350586     1\n",
       "0.572254     1\n",
       "0.951171     1\n",
       "0.378363     1\n",
       "Name: count, Length: 12637, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Kết hợp data: kết hợp categorical column (Director) với text column (Storyline)\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.sparse import hstack\n",
    "import pandas as pd\n",
    "\n",
    "# Tiền xử lý cột \"Director\"\n",
    "label_encoder = LabelEncoder()\n",
    "df['Director_encoded'] = label_encoder.fit_transform(df['Director'])\n",
    "\n",
    "# Chọn cột cần scale (ví dụ: 'numerical_column')\n",
    "numerical_data = df['Director_encoded'].values.reshape(-1, 1)\n",
    "\n",
    "# Áp dụng Min-Max Scaling\n",
    "scaler = MinMaxScaler()\n",
    "numerical_data_scaled = scaler.fit_transform(numerical_data)\n",
    "\n",
    "# Thay thế cột gốc bằng cột đã scale\n",
    "df['Director_encoded'] = numerical_data_scaled\n",
    "df['Director_encoded'].value_counts()\n",
    "\n",
    "# Tạo DataFrame mới với các cột cần thiết\n",
    "# selected_columns = ['Director_encoded', 'Storyline', 'Genre']\n",
    "# df_selected = df[selected_columns]\n",
    "\n",
    "# df_0 = df_selected[df_selected['Genre'].apply(lambda x: 'drama' in x)]\n",
    "# df_1 = df_selected[df_selected['Genre'].apply(lambda x: 'drama' not in x)]\n",
    "\n",
    "# # Chia thành tập huấn luyện và tập kiểm thử với tỉ lệ 70-30\n",
    "# train_df_0, test_df_0 = train_test_split(df_0, test_size=0.3, random_state=42)\n",
    "# train_df_1, test_df_1 = train_test_split(df_1, test_size=0.3, random_state=42)\n",
    "\n",
    "# # Kết hợp lại để tạo tập huấn luyện và tập kiểm thử cuối cùng\n",
    "# train_df = pd.concat([train_df_0, train_df_1], axis=0)\n",
    "# test_df = pd.concat([test_df_0, test_df_1], axis=0)\n",
    "\n",
    "# X_train_text = [' '.join(row) for row in train_df['Storyline'].values]\n",
    "# X_test_text = [' '.join(row) for row in test_df['Storyline'].values]\n",
    "\n",
    "# # Sử dụng TF-IDF để biểu diễn văn bản\n",
    "# tfidf_vectorizer = TfidfVectorizer()\n",
    "# X_train_tfidf = tfidf_vectorizer.fit_transform(X_train_text)\n",
    "# X_test_tfidf = tfidf_vectorizer.transform(X_test_text)\n",
    "\n",
    "# # Kết hợp với cột \"Director_encoded\"\n",
    "# X_train_combined = hstack([X_train_tfidf, train_df['Director_encoded'].values.reshape(-1, 1)])\n",
    "# X_test_combined = hstack([X_test_tfidf, test_df['Director_encoded'].values.reshape(-1, 1)])\n",
    "\n",
    "# # Chuẩn hóa dữ liệu sử dụng StandardScaler\n",
    "# scaler = StandardScaler(with_mean=False)\n",
    "# X_train_combined_scaled = scaler.fit_transform(X_train_combined)\n",
    "# X_test_combined_scaled = scaler.transform(X_test_combined)\n",
    "\n",
    "# y_train = ['drama' in value for value in train_df['Genre'].values]\n",
    "# y_test = ['drama' in value for value in test_df['Genre'].values]\n",
    "\n",
    "# # Huấn luyện mô hình SVM\n",
    "# svm_model = SVC(kernel='linear')\n",
    "# svm_model.fit(X_train_combined_scaled, y_train)\n",
    "\n",
    "# # Dự đoán trên tập kiểm tra\n",
    "# y_pred = svm_model.predict(X_test_combined_scaled)\n",
    "\n",
    "# # Đánh giá mô hình\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# recall = recall_score(y_test, y_pred)\n",
    "# f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# print(\"Accuracy: \" + str(accuracy))\n",
    "# print(\"Recall: \" + str(recall))\n",
    "# print(\"F1-score: \" + str(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7ed6ccd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kingk\\AppData\\Local\\Temp\\ipykernel_5924\\969368509.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected[numerical_columns] = scaler.fit_transform(df_selected[numerical_columns])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [16405, 18748]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 45\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Huấn luyện mô hình SVM\u001b[39;00m\n\u001b[0;32m     44\u001b[0m svm_model \u001b[38;5;241m=\u001b[39m SVC(kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 45\u001b[0m \u001b[43msvm_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Dự đoán trên tập kiểm tra\u001b[39;00m\n\u001b[0;32m     48\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m svm_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:190\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    188\u001b[0m     check_consistent_length(X, y)\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 190\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    199\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_targets(y)\n\u001b[0;32m    201\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\n\u001b[0;32m    202\u001b[0m     [] \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m sample_weight, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64\n\u001b[0;32m    203\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:622\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    620\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    621\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 622\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    623\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1164\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1146\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1147\u001b[0m     X,\n\u001b[0;32m   1148\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1159\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1160\u001b[0m )\n\u001b[0;32m   1162\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m-> 1164\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:407\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    405\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 407\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    408\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    409\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    410\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [16405, 18748]"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Giả sử df chứa cột 'Certificate', 'Director', 'Genre'\n",
    "\n",
    "# Tiền xử lý cột \"Certificate\" và \"Director\"\n",
    "label_encoder_cert = LabelEncoder()\n",
    "df['Certificate_encoded'] = label_encoder_cert.fit_transform(df['Certificate'])\n",
    "\n",
    "label_encoder_dir = LabelEncoder()\n",
    "df['Director_encoded'] = label_encoder_dir.fit_transform(df['Director'])\n",
    "\n",
    "# Chọn cột cần sử dụng\n",
    "selected_columns = ['Certificate_encoded', 'Director_encoded', 'Genre']\n",
    "\n",
    "# Chọn dữ liệu từ các cột đã chọn\n",
    "df_selected = df[selected_columns]\n",
    "\n",
    "# Chuẩn hóa dữ liệu số\n",
    "numerical_columns = ['Certificate_encoded', 'Director_encoded']\n",
    "scaler = MinMaxScaler()\n",
    "df_selected[numerical_columns] = scaler.fit_transform(df_selected[numerical_columns])\n",
    "\n",
    "# Stratified Sampling: chia 70-30 ở True_df và False_df rồi kết hợp\n",
    "df_0 = df_selected[df_selected['Genre'].apply(lambda x: 'drama' in x)]\n",
    "df_1 = df_selected[df_selected['Genre'].apply(lambda x: 'drama' not in x)]\n",
    "\n",
    "# Chia thành tập huấn luyện và tập kiểm thử với tỉ lệ 70-30\n",
    "train_df_0, test_df_0 = train_test_split(df_0, test_size=0.3, random_state=42)\n",
    "train_df_1, test_df_1 = train_test_split(df_1, test_size=0.3, random_state=42)\n",
    "\n",
    "# Kết hợp lại để tạo tập huấn luyện và tập kiểm thử cuối cùng\n",
    "train_df = pd.concat([train_df_0, train_df_1], axis=0)\n",
    "test_df = pd.concat([test_df_0, test_df_1], axis=0)\n",
    "\n",
    "# Chọn các cột số cần sử dụng\n",
    "X_train = train_df[numerical_columns]\n",
    "X_test = test_df[numerical_columns]\n",
    "\n",
    "# Huấn luyện mô hình SVM\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Dự đoán trên tập kiểm tra\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Đánh giá mô hình\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# print(\"Accuracy: \" + str(accuracy))\n",
    "# print(\"Recall: \" + str(recall))\n",
    "# print(\"F1-score: \" + str(f1))\n",
    "unique_values, counts = np.unique(y_pred, return_counts=True)\n",
    "\n",
    "# Tạo DataFrame để hiển thị kết quả\n",
    "result_df = pd.DataFrame({'Value': unique_values, 'Count': counts})\n",
    "\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1af88d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kingk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_array_api.py:380: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  array = numpy.asarray(array, order=order, dtype=dtype)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You appear to be using a legacy multi-label data representation. Sequence of sequences are no longer supported; use a binary array or sparse matrix instead - the MultiLabelBinarizer transformer can convert to this format.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 30\u001b[0m\n\u001b[0;32m     28\u001b[0m svm_model \u001b[38;5;241m=\u001b[39m SVC(kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Chú ý rằng chúng ta sử dụng mảng 1D làm nhãn, không phải ma trận nhị phân\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m \u001b[43msvm_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_tfidf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Dự đoán trên tập kiểm thử\u001b[39;00m\n\u001b[0;32m     33\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m svm_model\u001b[38;5;241m.\u001b[39mpredict(X_test_tfidf)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:199\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    190\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    191\u001b[0m         X,\n\u001b[0;32m    192\u001b[0m         y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    196\u001b[0m         accept_large_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    197\u001b[0m     )\n\u001b[1;32m--> 199\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\n\u001b[0;32m    202\u001b[0m     [] \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m sample_weight, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64\n\u001b[0;32m    203\u001b[0m )\n\u001b[0;32m    204\u001b[0m solver_type \u001b[38;5;241m=\u001b[39m LIBSVM_IMPL\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_impl)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:743\u001b[0m, in \u001b[0;36mBaseSVC._validate_targets\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    741\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_targets\u001b[39m(\u001b[38;5;28mself\u001b[39m, y):\n\u001b[0;32m    742\u001b[0m     y_ \u001b[38;5;241m=\u001b[39m column_or_1d(y, warn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 743\u001b[0m     \u001b[43mcheck_classification_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    744\u001b[0m     \u001b[38;5;28mcls\u001b[39m, y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y_, return_inverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    745\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight_ \u001b[38;5;241m=\u001b[39m compute_class_weight(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight, classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcls\u001b[39m, y\u001b[38;5;241m=\u001b[39my_)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\multiclass.py:208\u001b[0m, in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_classification_targets\u001b[39m(y):\n\u001b[0;32m    197\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Ensure that target y is of a non-regression type.\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \n\u001b[0;32m    199\u001b[0m \u001b[38;5;124;03m    Only the following target types (as defined in type_of_target) are allowed:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;124;03m        Target values.\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m \u001b[43mtype_of_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[0;32m    210\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    211\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    214\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-sequences\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    215\u001b[0m     ]:\n\u001b[0;32m    216\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    217\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown label type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Maybe you are trying to fit a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    218\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier, which expects discrete classes on a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    219\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregression target with continuous values.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    220\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\multiclass.py:347\u001b[0m, in \u001b[0;36mtype_of_target\u001b[1;34m(y, input_name)\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    342\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    343\u001b[0m         \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(y[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__array__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    344\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(y[\u001b[38;5;241m0\u001b[39m], Sequence)\n\u001b[0;32m    345\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(y[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mstr\u001b[39m)\n\u001b[0;32m    346\u001b[0m     ):\n\u001b[1;32m--> 347\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    348\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou appear to be using a legacy multi-label data\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    349\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m representation. Sequence of sequences are no\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    350\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m longer supported; use a binary array or sparse\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    351\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m matrix instead - the MultiLabelBinarizer\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    352\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m transformer can convert to this format.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    353\u001b[0m         )\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n\u001b[0;32m    355\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: You appear to be using a legacy multi-label data representation. Sequence of sequences are no longer supported; use a binary array or sparse matrix instead - the MultiLabelBinarizer transformer can convert to this format."
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "\n",
    "# Giả sử df chứa cột 'Storyline' và 'Genre', mỗi mẫu có thể thuộc nhiều lớp\n",
    "\n",
    "# Chia dữ liệu thành tập huấn luyện và tập kiểm thử\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Sử dụng MultiLabelBinarizer để chuyển đổi chuỗi nhãn thành ma trận nhị phân\n",
    "mlb = MultiLabelBinarizer()\n",
    "y_train_bin = mlb.fit_transform(train_df['Genre'])\n",
    "y_test_bin = mlb.transform(test_df['Genre'])\n",
    "\n",
    "# Chuyển đổi ma trận nhị phân thành mảng 1D\n",
    "y_train = mlb.inverse_transform(y_train_bin)\n",
    "y_test = mlb.inverse_transform(y_test_bin)\n",
    "\n",
    "# Biểu diễn văn bản sử dụng TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(train_df['Storyline'])\n",
    "X_test_tfidf = tfidf_vectorizer.transform(test_df['Storyline'])\n",
    "\n",
    "# Huấn luyện mô hình SVC\n",
    "svm_model = SVC(kernel='linear')\n",
    "# Chú ý rằng chúng ta sử dụng mảng 1D làm nhãn, không phải ma trận nhị phân\n",
    "svm_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Dự đoán trên tập kiểm thử\n",
    "y_pred = svm_model.predict(X_test_tfidf)\n",
    "\n",
    "# Đánh giá mô hình\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_report_str = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:')\n",
    "print(classification_report_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3830a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
